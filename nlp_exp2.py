# -*- coding: utf-8 -*-
"""NLP_exp2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14oMrqIXZpfwtYcuaepEj5cPD96L-vXBI
"""

import nltk
 nltk.download('punkt')

from nltk.stem import PorterStemmer
from nltk.tokenize import word_tokenize
  
ps = PorterStemmer()
  
sentence = "Programmers program with programming languages"
words = word_tokenize(sentence)
  
for w in words:
    print(w, " : ", ps.stem(w))

file=open("/content/Nlp_exp2_input")
my_lines_list=file.readlines()
my_lines_list

from nltk.tokenize import sent_tokenize, word_tokenize
from nltk.stem import PorterStemmer

porter=PorterStemmer()

def stemSentence(sentence):
    token_words=word_tokenize(sentence)
    token_words
    stem_sentence=[]
    for word in token_words:
        stem_sentence.append(porter.stem(word))
        stem_sentence.append(" ")
    return "".join(stem_sentence)

print(my_lines_list[1])
print("Stemmed sentence")
x=stemSentence(my_lines_list[1])
print(x)

import nltk
 nltk.download('wordnet')

#lemmatization:
import nltk
from nltk.stem import WordNetLemmatizer
wordnet_lemmatizer = WordNetLemmatizer()

sentence = "There are many different types of corpora available that you can use with varying types of projects, for example, a selection of free electronic books, web and chat text and news documents on different genres."

punctuations="?:!.,;"
sentence_words = nltk.word_tokenize(sentence)
for word in sentence_words:
    if word in punctuations:
        sentence_words.remove(word)

sentence_words
print("{0:20}{1:20}".format("Word","Lemma"))

for word in sentence_words:
    print ("{0:20}{1:20}".format(word,wordnet_lemmatizer.lemmatize(word, pos="v")))

#regular expressions
#in-text citations

!pip install refextract
!pip install python-magic

#extract the references
from refextract import extract_references_from_file
references = extract_references_from_file('/content/Research_paper_recommendation_with_topic_analysis.pdf')
print(references[0])

import re

file=open("/content/Nlp_exp2_input")
my_lines_list=file.readlines()
my_lines_list

pattern = "\d{2}[/-]\d{2}[/-]\d{4}"

dates = re.findall(pattern, my_lines_list[2])
for date in dates:
    if "-" in date:
        day, month, year = map(int, date.split("-"))
    else:
        day, month, year = map(int, date.split("/"))
    if 1 <= day <= 31 and 1 <= month <= 12:
        print(year)

#7.extract all the abbreviations in the given text document
import re
rx = r"\b[A-Z](?=([&.]?))(?:\1[A-Z])+\b"
s = "My name is Rob. My friend works at (C.I.). Indian Army(IA). B&W also CHT Also I...A"
print( [x.group() for x in re.finditer(rx, s)] )

!pip install locationtagger

import nltk
nltk.download('averaged_perceptron_tagger')

import nltk
nltk.download('maxent_ne_chunker')

import nltk
nltk.download('words')

file=open("/content/Nlp_exp2_input1")
my_lines_list=file.readlines()
my_lines_list

#extracting cities
import locationtagger
  
# initializing sample text
sample_text = "India has very rich and vivid culture\
       widely spread from Kerala to Nagaland to Haryana to Maharashtra. " \
       "Delhi being capital with Mumbai financial capital.\
       Can be said better than some western cities such as " \
       " Munich, London etc. Pakistan and Bangladesh share its borders"
  
  
# extracting entities.
place_entity = locationtagger.find_locations(text = sample_text)

  
# getting all cities
print("The cities in text : ")
print(place_entity.cities)

#extract as long as and is a 
import re
input=" The car will keep running as long as you take good care of it. I will be staying at her apartment as long as she takes to come back. As long as I know where to go I will manage to find the directions. The food will be delivered to your doorstep for as long as you want it.As long as her kids come back in time she does not question where they are going. Source: theidioms.com"
print('Sentence with AS LONG AS:\n')
re.findall(r"([^.]*?as long as[^.]*\.)",input,flags=re.IGNORECASE)

print('Sentence with IS A:\n')
input1="TC39 is a proposal to add pattern matching to JavaScript.Sometimes we want to specify a default action if no pattern was matched.It is a wildcard pattern and matches anything that was not matched by the other case statements. The pattern int(num1), int(num2) is a class pattern that checks whether num1 and num2 are both of type int."
re.findall(r"([^.]*?is a[^.]*\.)",input1,flags=re.IGNORECASE)

#extracting before and after:
input_corpus = "Trees such as oaks and elms don’t grow at this altitude.\n If the specific examples aren’t essential to the accuracy of your sentence, then use a comma.his year we’d like to visit a place such as Greece or Rome"
re.findall(r'(?:^|\S+\s+\S+)(?:\s*\S+\s+\S+|$)', input_corpus)